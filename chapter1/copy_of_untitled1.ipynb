{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKg3e31Nn8Lh2dTVwsSus/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/milox6m/MachinLerning2025/blob/main/chapter1/copy_of_untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "f9Pgsmj8MbRV",
        "outputId": "dc9ca840-c0ed-4ce9-f14d-1d3f20313006"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'dataset'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1119619ef630>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mopenai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medit_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalculate_classification_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_classification_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./../dataset/test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dataset'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import re\n",
        "import sys\n",
        "import time\n",
        "sys.path.insert(0, './..')\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "from dataset.edit_dataset import load_dataset\n",
        "from utils.result import calculate_classification_metric, write_classification_metric\n",
        "dataset = load_dataset('./../dataset/test.csv')\n",
        "model = 'gpt-4-0125-preview'\n",
        "prompt = [\n",
        "    {\n",
        "        'role': 'system',\n",
        "        'content': '\\\n",
        "            You will be provided with a string. \\\n",
        "            Distinguish if the string causes SQL injection as a web security specialist.\\\n",
        "            If the string can cause SQL injection, return 1. If not, return 0.\\\n",
        "            Return only result for answer. Do not explain the result.'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': '<string>\\' or \\'a\\' = \\'a</string>'\n",
        "    },\n",
        "    {\n",
        "        'role': 'assistant',\n",
        "        'content': '1'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': '<string>Hello.</string>'\n",
        "    },\n",
        "    {\n",
        "        'role': 'assistant',\n",
        "        'content': '0'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': '<string>I am a Japanese<./string>'\n",
        "    },\n",
        "    {\n",
        "        'role': 'assistant',\n",
        "        'content': '0'\n",
        "    },\n",
        "    {\n",
        "        'role': 'user',\n",
        "        'content': '<string>-3756\\' )  union all select 1034,1034,1034--</string>'\n",
        "    },\n",
        "    {\n",
        "        'role': 'assistant',\n",
        "        'content': '1'\n",
        "    }\n",
        "]\n",
        "classification_counts = {\n",
        "    'true_positives': 0,\n",
        "    'false_positives': 0,\n",
        "    'true_negatives': 0,\n",
        "    'false_negatives': 0\n",
        "}\n",
        "inference_time = []\n",
        "labels = []\n",
        "raw_queries = []\n",
        "preds = []\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "for i, (query, label) in enumerate(dataset[:500]):\n",
        "    print('i', i)\n",
        "    prompt.append(\n",
        "        {\n",
        "            'role': 'user',\n",
        "            'content': f'<string>{query}</string>'\n",
        "        })\n",
        "\n",
        "    start_time = time.time()\n",
        "    chat_completion = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=prompt,\n",
        "        temperature=0.1,\n",
        "        max_tokens=2\n",
        "    )\n",
        "    inference_time.append(time.time() - start_time)\n",
        "\n",
        "    response = chat_completion.choices[0].message.content\n",
        "    print('response:', response)\n",
        "    try:\n",
        "        result = int(re.search(r'(\\d+)', response).group(1))\n",
        "    except ValueError:\n",
        "        result = 'N/A'\n",
        "    except AttributeError:\n",
        "        result = 'N/A'\n",
        "\n",
        "    labels.append(int(label))\n",
        "    raw_queries.append(query)\n",
        "    preds.append(result)\n",
        "\n",
        "\n",
        "    print(result, label)\n",
        "    prompt.pop(9)\n",
        "\n",
        "calculate_classification_metric(classification_counts, labels, preds, raw_queries)\n",
        "write_classification_metric(classification_counts, inference_time)"
      ]
    }
  ]
}